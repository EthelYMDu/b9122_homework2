{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DROM B9122\n",
    "# Homework Assignment 2\n",
    "Yumeng Du, yd2662  \n",
    "Oct 4, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please change it to your directory\n",
    "# or leave it blank to create output txt file under the current directory\n",
    "output_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (80 points)\n",
    "Write web crawlers for the following two tasks:\n",
    "\n",
    "1. Extract at least 10 United Nations press releases containing the word “crisis”. Start with the following seed url: \n",
    "<a>https://press.un.org/en.</a>\n",
    "Notice how press release pages have the “PRESS RELEASE” relative link in the top left corner. Here is an example press release: \n",
    "<a>https://press.un.org/en/2023/sc15431.doc.htm </a>\n",
    "where the “PRESS RELEASE” has the following relative anchor tag:  \n",
    "<span style=\"font-family:Courier New;\">\\<a href=\"/en/press-release\" hreflang=\"en\">Press Release\\</a></span>  \n",
    "Use this information to determine whether the web page is a press release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# define functions\n",
    "def check_crisis(childpage):\n",
    "    '''\n",
    "    Input: \n",
    "        * childpage: bs4.BeautifulSoup\n",
    "    Output:\n",
    "        * Boolean, whether the childpage is for an press release with word \"crisis\"\n",
    "    ---------------------------------------------------------------------------------\n",
    "    This function check whether the given webpage is a press release based on tag <a href=\"/en/press-release\" hreflang=\"en\">Press Release</a>\n",
    "    then check whether it is a press release contains word \"crisis\"\n",
    "        * Only perform check on the headline and body of the news article. e.g. If the sidebar of the webpage contains a link to another article with title \"crisis\" , we don't count it as a crisis article\n",
    "        * the function identify headline by tag 'h1' with class=\"page-header\"\n",
    "        * the function identify body part by tag 'div' with class=\"field field--name-body field--type-text-with-summary field--label-hidden field__item\"\n",
    "    '''\n",
    "    if childpage.find('a', **{'href':\"/en/press-release\",\n",
    "                                'hreflang':\"en\",\n",
    "                                'text':'Press Release'})is not None: # it is a press release!\n",
    "        global header \n",
    "        header = childpage.find('h1', {'class':\"page-header\"}).get_text()\n",
    "        global body \n",
    "        body = childpage.find('div', {'class':\"field field--name-body field--type-text-with-summary field--label-hidden field__item\"}).get_text()\n",
    "        \n",
    "        if (\"crisis\" in header.lower()) or (\"crisis\" in body.lower()):\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "    # not press release, will return None\n",
    "\n",
    "def examine_links(results_page_a,seen_a,crisis_release_a,check_fun):\n",
    "    '''\n",
    "    Input: \n",
    "        * results_page: bs4.BeautifulSoup, the webpage with its links to examine\n",
    "        * seen_a: list collecting url already examined\n",
    "        * crisis_release_a: list collecting url satisified the criteria defined by check_fun\n",
    "        * check_fun: function defining the criteria\n",
    "    Output:\n",
    "        * updated (seen_a, crisis_release_a)\n",
    "    ---------------------------------------------------------------------------------\n",
    "    This function check all links in results_page with tag a and hreflang=\"en\", whether they satisfy certain criteria\n",
    "    '''\n",
    "    for tag in tqdm.tqdm(results_page_a.find_all('a', href = True, hreflang=\"en\")): #find tags with links\n",
    "        # find child url\n",
    "        childUrl = tag['href'] #extract just the link\n",
    "        childUrl = urllib.parse.urljoin(seed_url, childUrl)\n",
    "        # only examine those url we haven't examined\n",
    "        if (seed_url in childUrl) and (childUrl not in seen_a):\n",
    "            # add the examining one to seen list\n",
    "            seen_a.append(childUrl)\n",
    "            # go the chilurl and extract its html soruce code\n",
    "            childpage = BeautifulSoup(requests.get(childUrl).content)\n",
    "            # check and put it into crisis_release_a if it satisfies the criteria\n",
    "            if check_fun(childpage):\n",
    "                  crisis_release_a.append([header, childUrl,body, childpage])\n",
    "        else:pass # already seen url, just ignore it\n",
    "    return seen_a, crisis_release_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only get 2 press release with word 'crisis' using the crrent seed url\n",
      "https://press.un.org/en\n",
      "will go to https://press.un.org/en/content/press-release\n",
      "\n",
      "\n",
      "examining:https://press.un.org/en/content/press-release\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 66289.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 crisis news found\n",
      "Have already examined 21 pieces of news\n",
      "\n",
      "\n",
      "examining:https://press.un.org/en/content/press-release?page=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 crisis news found\n",
      "Have already examined 31 pieces of news\n",
      "\n",
      "\n",
      "examining:https://press.un.org/en/content/press-release?page=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 crisis news found\n",
      "Have already examined 41 pieces of news\n",
      "\n",
      "\n",
      "examining:https://press.un.org/en/content/press-release?page=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 crisis news found\n",
      "Have already examined 51 pieces of news\n",
      "\n",
      "\n",
      "examining:https://press.un.org/en/content/press-release?page=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 crisis news found\n",
      "Have already examined 61 pieces of news\n",
      "\n",
      "\n",
      "examining:https://press.un.org/en/content/press-release?page=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 crisis news found\n",
      "Have already examined 71 pieces of news\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "      <th>html source code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‘Outrageous a Person Dies of Hunger Every Few ...</td>\n",
       "      <td>https://press.un.org/en/2023/sgsm21980.doc.htm</td>\n",
       "      <td>Following is UN Secretary-General António Gute...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marking International Day, Secretary-General S...</td>\n",
       "      <td>https://press.un.org/en/2023/sgsm21978.doc.htm</td>\n",
       "      <td>Following is UN Secretary-General António Gute...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stressing ‘1.5°C Limit Is Possible’, Secretary...</td>\n",
       "      <td>https://press.un.org/en/2023/sgsm21967.doc.htm</td>\n",
       "      <td>Following is the text of UN Secretary-General ...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‘Let’s Unite, Fight Together to Keep Promise o...</td>\n",
       "      <td>https://press.un.org/en/2023/dsgsm1877.doc.htm</td>\n",
       "      <td>Following are UN Deputy Secretary-General Amin...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‘Small Island States Do Not Lack Ambition, The...</td>\n",
       "      <td>https://press.un.org/en/2023/sgsm21959.doc.htm</td>\n",
       "      <td>Following is the text of UN Secretary-General ...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Welcoming Pact, Secretary-General Tells Summit...</td>\n",
       "      <td>https://press.un.org/en/2023/sgsm21956.doc.htm</td>\n",
       "      <td>Following are UN Secretary-General António Gut...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United Nations Charter ‘A How-To Manual’ on Co...</td>\n",
       "      <td>https://press.un.org/en/2023/sgsm21952.doc.htm</td>\n",
       "      <td>Following are UN Secretary-General António Gut...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global Leaders Must Take Action to Reduce Emis...</td>\n",
       "      <td>https://press.un.org/en/2023/sgsm21951.doc.htm</td>\n",
       "      <td>Following are UN Secretary-General António Gut...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Calling for Creative, Practical Financing Solu...</td>\n",
       "      <td>https://press.un.org/en/2023/sgsm21950.doc.htm</td>\n",
       "      <td>Following are UN Secretary-General António Gut...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>World Needs ‘Statesmanship, Not Gamesmanship a...</td>\n",
       "      <td>https://press.un.org/en/2023/sgsm21947.doc.htm</td>\n",
       "      <td>Following is UN Secretary-General António Gute...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sustainable Development Goals Require Global R...</td>\n",
       "      <td>https://press.un.org/en/2023/sgsm21945.doc.htm</td>\n",
       "      <td>Following are UN Secretary-General António Gut...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;meta charset=\"utf-8\"/&gt;, \\n, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               header  \\\n",
       "0   ‘Outrageous a Person Dies of Hunger Every Few ...   \n",
       "1   Marking International Day, Secretary-General S...   \n",
       "2   Stressing ‘1.5°C Limit Is Possible’, Secretary...   \n",
       "3   ‘Let’s Unite, Fight Together to Keep Promise o...   \n",
       "4   ‘Small Island States Do Not Lack Ambition, The...   \n",
       "5   Welcoming Pact, Secretary-General Tells Summit...   \n",
       "6   United Nations Charter ‘A How-To Manual’ on Co...   \n",
       "7   Global Leaders Must Take Action to Reduce Emis...   \n",
       "8   Calling for Creative, Practical Financing Solu...   \n",
       "9   World Needs ‘Statesmanship, Not Gamesmanship a...   \n",
       "10  Sustainable Development Goals Require Global R...   \n",
       "\n",
       "                                               url  \\\n",
       "0   https://press.un.org/en/2023/sgsm21980.doc.htm   \n",
       "1   https://press.un.org/en/2023/sgsm21978.doc.htm   \n",
       "2   https://press.un.org/en/2023/sgsm21967.doc.htm   \n",
       "3   https://press.un.org/en/2023/dsgsm1877.doc.htm   \n",
       "4   https://press.un.org/en/2023/sgsm21959.doc.htm   \n",
       "5   https://press.un.org/en/2023/sgsm21956.doc.htm   \n",
       "6   https://press.un.org/en/2023/sgsm21952.doc.htm   \n",
       "7   https://press.un.org/en/2023/sgsm21951.doc.htm   \n",
       "8   https://press.un.org/en/2023/sgsm21950.doc.htm   \n",
       "9   https://press.un.org/en/2023/sgsm21947.doc.htm   \n",
       "10  https://press.un.org/en/2023/sgsm21945.doc.htm   \n",
       "\n",
       "                                                 body  \\\n",
       "0   Following is UN Secretary-General António Gute...   \n",
       "1   Following is UN Secretary-General António Gute...   \n",
       "2   Following is the text of UN Secretary-General ...   \n",
       "3   Following are UN Deputy Secretary-General Amin...   \n",
       "4   Following is the text of UN Secretary-General ...   \n",
       "5   Following are UN Secretary-General António Gut...   \n",
       "6   Following are UN Secretary-General António Gut...   \n",
       "7   Following are UN Secretary-General António Gut...   \n",
       "8   Following are UN Secretary-General António Gut...   \n",
       "9   Following is UN Secretary-General António Gute...   \n",
       "10  Following are UN Secretary-General António Gut...   \n",
       "\n",
       "                                     html source code  \n",
       "0   [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  \n",
       "1   [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  \n",
       "2   [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  \n",
       "3   [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  \n",
       "4   [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  \n",
       "5   [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  \n",
       "6   [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  \n",
       "7   [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  \n",
       "8   [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  \n",
       "9   [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  \n",
       "10  [html, [\\n, [\\n, <meta charset=\"utf-8\"/>, \\n, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_url = \"https://press.un.org/en\"\n",
    "response = requests.get(seed_url)\n",
    "if response.status_code == 200: print(\"Success\")\n",
    "else: print(\"Failure\")\n",
    "\n",
    "results_page = BeautifulSoup(response.content)\n",
    "\n",
    "# check whether our seed url contains press release with word \"crisis\"\n",
    "seen = [seed_url]    #stack of urls seen so far\n",
    "crisis_release = []\n",
    "\n",
    "seen, crisis_release = examine_links(results_page,seen,crisis_release,check_crisis)\n",
    "\n",
    "# get the page to find more press release\n",
    "morelinks = results_page.find_all('div',{'class':'more-link'})\n",
    "press_r_latest = [x for x in morelinks if x.get_text()==\"Latest Press Releases\"][0].find(\"a\")['href']\n",
    "\n",
    "# check whether we have already obtained at least 10 press release with word \"crisis\"\n",
    "if len(crisis_release)>=10:\n",
    "      pd.DataFrame(crisis_release,columns=['header','url','body','html source code'])\n",
    "else:\n",
    "      print(f\"Only get {len(crisis_release)} press release with word 'crisis' using the crrent seed url\\n{seed_url}\\nwill go to {press_r_latest}\")\n",
    "\n",
    "      # go to the page for press releases\n",
    "      new_url = press_r_latest\n",
    "      ii = 0\n",
    "\n",
    "      while (len(crisis_release)<10): # continue until we find at least press release with word \"crisis\"\n",
    "            print(\"\\n\\nexamining:\"+new_url)\n",
    "            response = requests.get(new_url)\n",
    "            if response.status_code == 200: pass\n",
    "            else: \n",
    "                  print(\"Failure to connect\")\n",
    "                  break\n",
    "            \n",
    "            results_page = BeautifulSoup(response.content)\n",
    "            seen, crisis_release = examine_links(results_page,seen,crisis_release,check_crisis)\n",
    "            print(f'{len(crisis_release)} crisis news found\\nHave already examined {len(seen)} pieces of news')\n",
    "            \n",
    "            try:\n",
    "                  # find the button for next page and extract the link of next page\n",
    "                  pageurl = results_page.find('a',{'title':f'Go to next page',\n",
    "                                                      'rel':\"next\", \n",
    "                                                      'class':\"page-link\"})['href']\n",
    "                  # update new_url\n",
    "                  new_url = urllib.parse.urljoin(press_r_latest, pageurl)\n",
    "            except:\n",
    "                  print(\"No further page to explore\")\n",
    "                  break\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(crisis_release,columns=['header','url','body','html source code'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write press release with word \"crisis\" html source code into txt file\n",
    "ii=0\n",
    "while ii<10:\n",
    "    f= open(f\"{output_path}1_{ii+1}.txt\",\"w+\")\n",
    "    f.write(str(crisis_release[ii][3]))\n",
    "    f.close()\n",
    "    ii+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Crawl the press room of the European Parliament and extract at least 10 press releases that cover the plenary sessions and contain the word “crisis”. Start with the following seed url:\n",
    "https://www.europarl.europa.eu/news/en/press-room  \n",
    "Notice how press releases related to plenary sessions contain the text “PLENARY SESSIONS” with the following html:  \n",
    "<span style=\"font-family:Courier New;\">\\<span class=\"ep_name\">Plenary session\\</span></span>    \n",
    "Here is an example:\n",
    "https://www.europarl.europa.eu/news/en/press-room/20220620IPR33417/national-recovery-plans-meps-assess--the-performance-of-crisis-funding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_crisis(childpage):\n",
    "    '''\n",
    "    Input: \n",
    "        * childpage: bs4.BeautifulSoup\n",
    "    Output:\n",
    "        * Boolean, whether the childpage is for an press release with word \"crisis\" and covering plenary sessions\n",
    "    ---------------------------------------------------------------------------------\n",
    "    This function check whether the given webpage is a press release covering plenary sessions based on tag <span class=\"ep_name\">Plenary session</span>\n",
    "    then check whether it is a press release contains word \"crisis\"\n",
    "        * Only perform check on the headline and body of the news article. e.g. If the sidebar of the webpage contains a link to another article with title \"crisis\" , we don't count it as a crisis article\n",
    "        * the function identify headline by tag 'h1' with class=\"ep_title\"\n",
    "        * the function identify body part by finding all tag 'div' with class=\"ep_gridcolumn\", 'data-view1200':\"6\" and the first tag will be for title, and second one is for body // no better method identified\n",
    "    '''\n",
    "    if childpage.find('span', **{'class':\"ep_name\",\n",
    "                                'text':'Plenary session'})is not None: # it is a press release!\n",
    "        global header \n",
    "        header = childpage.find('h1', {'class':\"ep_title\"}).find('span',{'class','ep_name'}).get_text()\n",
    "        global body \n",
    "        body = childpage.find_all('div', {'class':\"ep_gridcolumn\",\n",
    "                       'data-view1200':\"6\"})[1].get_text()\n",
    "\n",
    "        if ((\"crisis\" in header.lower()) or (\"crisis\" in body.lower())):\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "    # not press release, will return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_crisis_more_page(seen_a,crisis_release_a):\n",
    "      '''\n",
    "      Input: \n",
    "            * seen_a: list collecting url already examined\n",
    "            * crisis_release_a: list collecting url satisified the criteria defined by check_fun\n",
    "      Output:\n",
    "            * updated (seen_a, crisis_release_a)\n",
    "      ---------------------------------------------------------------------------------\n",
    "      This function extract html code from the updated webdriver and check all links in webpage, whether they satisfy certain criteria\n",
    "      '''\n",
    "      html = driver.page_source\n",
    "      global more_loads\n",
    "      more_loads= BeautifulSoup(html,'lxml')\n",
    "      seen_b,crisis_release_b = detect_crisis_one_page(more_loads, seen_a,crisis_release_a, check_crisis)\n",
    "      return seen_b, crisis_release_b\n",
    "\n",
    "def detect_crisis_one_page(results_page_a,seen_a,crisis_release_a,check_fun):\n",
    "      '''\n",
    "      Input: \n",
    "            * results_page: bs4.BeautifulSoup, the webpage with its links to examine\n",
    "            * seen_a: list collecting url already examined\n",
    "            * crisis_release_a: list collecting url satisified the criteria defined by check_fun\n",
    "            * check_fun: function defining the criteria\n",
    "      Output:\n",
    "            * updated (seen_a, crisis_release_a)\n",
    "      ---------------------------------------------------------------------------------\n",
    "      This function check all links in results_page with tag article and class=\"ep_gridcolumn ep-m_product ep-layout_linkmode\", whether they satisfy certain criteria\n",
    "      '''\n",
    "      for tag in tqdm.tqdm(results_page_a.find_all('article',{'class':'ep_gridcolumn ep-m_product ep-layout_linkmode'})): #find tags with links\n",
    "            childUrl = tag.find(\"a\",{'href':True, 'title':\"Read more\"})['href'] # extract just the link\n",
    "            childUrl = urllib.parse.urljoin(seed_url, childUrl)\n",
    "\n",
    "            if seed_url in childUrl and childUrl not in seen_a:\n",
    "                  seen_a.append(childUrl)\n",
    "                  childpage = BeautifulSoup(requests.get(childUrl).content)\n",
    "                  if check_crisis(childpage):\n",
    "                        crisis_release_a.append([header, childUrl, body, childpage])\n",
    "            else: pass\n",
    "      return seen_a, crisis_release_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "loading more *1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:12<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 2 crisis related press release\n",
      "Already examine 31 pages\n",
      "\n",
      "\n",
      "loading more *2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:14<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 3 crisis related press release\n",
      "Already examine 46 pages\n",
      "\n",
      "\n",
      "loading more *3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:14<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 5 crisis related press release\n",
      "Already examine 61 pages\n",
      "\n",
      "\n",
      "loading more *4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:13<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 5 crisis related press release\n",
      "Already examine 76 pages\n",
      "\n",
      "\n",
      "loading more *5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:00<00:00, 71705.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 5 crisis related press release\n",
      "Already examine 76 pages\n",
      "\n",
      "\n",
      "loading more *6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:14<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 6 crisis related press release\n",
      "Already examine 91 pages\n",
      "\n",
      "\n",
      "loading more *7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:14<00:00,  8.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 6 crisis related press release\n",
      "Already examine 106 pages\n",
      "\n",
      "\n",
      "loading more *8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:13<00:00,  9.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 8 crisis related press release\n",
      "Already examine 121 pages\n",
      "\n",
      "\n",
      "loading more *9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:13<00:00, 11.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 9 crisis related press release\n",
      "Already examine 136 pages\n",
      "\n",
      "\n",
      "loading more *10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:14<00:00, 11.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 crisis related press release\n",
      "Already examine 151 pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import tqdm\n",
    "\n",
    "\n",
    "seed_url = \"https://www.europarl.europa.eu/news/en/press-room\"\n",
    "# This code is written for Google Chrome only, please make sure you have it installed\n",
    "driver = webdriver.Chrome()\n",
    "# will have a pop-up window showing the webpage for seed_url\n",
    "# IMPORTANT: Please do NOT close the pop-up window until you finish running all programs here!!!!!\n",
    "driver.get(seed_url)\n",
    "\n",
    "seen = [seed_url]    #stack of urls seen so far\n",
    "crisis_release = []          \n",
    "\n",
    "# get source code\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "# check whether seed_url have desired releases\n",
    "seen,crisis_release,  = detect_crisis_one_page(soup, seen,crisis_release, check_crisis)\n",
    "\n",
    "ii=0\n",
    "while (len(crisis_release)<10): # continue the process until we find at least 10 desired releases\n",
    "    print(f'\\n\\nloading more *{ii+1}')\n",
    "    # find the \"load more\" button on the page\n",
    "    element = driver.find_element(\"id\",'continuesLoading_button')\n",
    "    # click the \"load more button\"\n",
    "    # webdriver.ActionChains(driver).click(element).perform()\n",
    "    driver.execute_script(\"arguments[0].click();\", element)\n",
    "    # allow some time for the source code to update [sometimes 0.5s may not be sufficient, but in the next round, it will utlimately be updated]\n",
    "    time.sleep(0.5)\n",
    "    # perform check\n",
    "    seen, crisis_release = detect_crisis_more_page(seen,crisis_release)\n",
    "\n",
    "    print(f'found {len(crisis_release)} crisis related press release\\nAlready examine {len(seen)} pages')\n",
    "    ii+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "      <th>html source code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nagorno-Karabakh: MEPs demand review of EU rel...</td>\n",
       "      <td>https://www.europarl.europa.eu/news/en/press-r...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\nParliament says current situ...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;title&gt;Nagorno-Karabakh: MEPs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parliament argues for a top-up to multi-annual...</td>\n",
       "      <td>https://www.europarl.europa.eu/news/en/press-r...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\nRevision of EU multiannual f...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;title&gt;Parliament argues for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reduce demand and protect people in prostituti...</td>\n",
       "      <td>https://www.europarl.europa.eu/news/en/press-r...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\nDifferent regulations across...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;title&gt;Reduce demand and prot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Svietlana Tsikhanouskaya to MEPs: support Bela...</td>\n",
       "      <td>https://www.europarl.europa.eu/news/en/press-r...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n \\n \\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;title&gt;Svietlana Tsikhanouska...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEPs vote to strengthen EU defence industry th...</td>\n",
       "      <td>https://www.europarl.europa.eu/news/en/press-r...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\nA €300 million budget until ...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;title&gt;MEPs vote to strengthe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COVID-19: Parliament adopts roadmap to better ...</td>\n",
       "      <td>https://www.europarl.europa.eu/news/en/press-r...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\nEvaluation of the effectiven...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;title&gt;COVID-19: Parliament a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MEPs want to create a European Day for the vic...</td>\n",
       "      <td>https://www.europarl.europa.eu/news/en/press-r...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nParliament calls for an annual ‘EU...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;title&gt;MEPs want to create a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EP TODAY</td>\n",
       "      <td>https://www.europarl.europa.eu/news/en/press-r...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nThursday, 15 June\\n\\n\\n\\n\\n\\n\\nPar...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;title&gt;EP TODAY | News | Euro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>President Christodoulides: “no border changes ...</td>\n",
       "      <td>https://www.europarl.europa.eu/news/en/press-r...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n \\n \\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;title&gt;President Christodouli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EP Today</td>\n",
       "      <td>https://www.europarl.europa.eu/news/en/press-r...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nMonday, 12 June\\n\\n\\n\\n\\n\\n\\nLast-...</td>\n",
       "      <td>[html, [\\n, [\\n, &lt;title&gt;EP Today  | News | Eur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              header  \\\n",
       "0  Nagorno-Karabakh: MEPs demand review of EU rel...   \n",
       "1  Parliament argues for a top-up to multi-annual...   \n",
       "2  Reduce demand and protect people in prostituti...   \n",
       "3  Svietlana Tsikhanouskaya to MEPs: support Bela...   \n",
       "4  MEPs vote to strengthen EU defence industry th...   \n",
       "5  COVID-19: Parliament adopts roadmap to better ...   \n",
       "6  MEPs want to create a European Day for the vic...   \n",
       "7                                           EP TODAY   \n",
       "8  President Christodoulides: “no border changes ...   \n",
       "9                                          EP Today    \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.europarl.europa.eu/news/en/press-r...   \n",
       "1  https://www.europarl.europa.eu/news/en/press-r...   \n",
       "2  https://www.europarl.europa.eu/news/en/press-r...   \n",
       "3  https://www.europarl.europa.eu/news/en/press-r...   \n",
       "4  https://www.europarl.europa.eu/news/en/press-r...   \n",
       "5  https://www.europarl.europa.eu/news/en/press-r...   \n",
       "6  https://www.europarl.europa.eu/news/en/press-r...   \n",
       "7  https://www.europarl.europa.eu/news/en/press-r...   \n",
       "8  https://www.europarl.europa.eu/news/en/press-r...   \n",
       "9  https://www.europarl.europa.eu/news/en/press-r...   \n",
       "\n",
       "                                                body  \\\n",
       "0  \\n\\n\\n\\n\\n\\n\\n\\n\\nParliament says current situ...   \n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\n\\nRevision of EU multiannual f...   \n",
       "2  \\n\\n\\n\\n\\n\\n\\n\\n\\nDifferent regulations across...   \n",
       "3  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n \\n \\n\\n\\n\\n\\n\\n...   \n",
       "4  \\n\\n\\n\\n\\n\\n\\n\\n\\nA €300 million budget until ...   \n",
       "5  \\n\\n\\n\\n\\n\\n\\n\\n\\nEvaluation of the effectiven...   \n",
       "6  \\n\\n\\n\\n\\n\\nParliament calls for an annual ‘EU...   \n",
       "7  \\n\\n\\n\\n\\n\\nThursday, 15 June\\n\\n\\n\\n\\n\\n\\nPar...   \n",
       "8  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n \\n \\n\\n\\n\\n\\n\\n...   \n",
       "9  \\n\\n\\n\\n\\n\\nMonday, 12 June\\n\\n\\n\\n\\n\\n\\nLast-...   \n",
       "\n",
       "                                    html source code  \n",
       "0  [html, [\\n, [\\n, <title>Nagorno-Karabakh: MEPs...  \n",
       "1  [html, [\\n, [\\n, <title>Parliament argues for ...  \n",
       "2  [html, [\\n, [\\n, <title>Reduce demand and prot...  \n",
       "3  [html, [\\n, [\\n, <title>Svietlana Tsikhanouska...  \n",
       "4  [html, [\\n, [\\n, <title>MEPs vote to strengthe...  \n",
       "5  [html, [\\n, [\\n, <title>COVID-19: Parliament a...  \n",
       "6  [html, [\\n, [\\n, <title>MEPs want to create a ...  \n",
       "7  [html, [\\n, [\\n, <title>EP TODAY | News | Euro...  \n",
       "8  [html, [\\n, [\\n, <title>President Christodouli...  \n",
       "9  [html, [\\n, [\\n, <title>EP Today  | News | Eur...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(crisis_release,columns=['header','url','body','html source code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output html sources code into txt file\n",
    "ii=0\n",
    "while ii<10:\n",
    "    f= open(f\"{output_path}2_{ii+1}.txt\",\"w+\")\n",
    "    f.write(str(crisis_release[ii][3]))\n",
    "    f.close()\n",
    "    ii+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Create a Git repository on the GitHub platform. Name the repository <span style=\"font-family:Courier New;\">b9122_homework2</span>, make it publicly available and perform the following:\n",
    "* Populate the repository with the webcrawler code that we covered in class and the webcrawler code files that you created in Question 1.\n",
    "* Create a <span style=\"font-family:Courier New;\">README.md</span> file where you will provide information about the repository, including author information and a description of the code files\n",
    "* Make changes to at least one of the added files (whatever changes you prefer). \n",
    "* Update the repository with the edited file/s.\n",
    "* For those of you who will be doing the interaction with the github repository using git commands, perform the following:\n",
    "    * The <span style=\"font-family:Courier New;\">git log</span> command displays the commit logs. Use output redirection(“>”)tostore the output of this command in a file named <span style=\"font-family:Courier New;\">gitlog.txt</span>.Submit the <span style=\"font-family:Courier New;\">gitlog.txt</span> file and the <span style=\"font-family:Courier New;\">url</span> of your repository\n",
    "* For those of you who will be using the GitHub Desktop application, perform the following:\n",
    "    * The “History” tab displays the repository activities. Open this tab and take a screenshot.\n",
    "    Submit the screenshot image and the url of your repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**  \n",
    "https://github.com/EthelYMDu/b9122_homework2\n",
    "\n",
    "<img src=\"gitdesktop.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
